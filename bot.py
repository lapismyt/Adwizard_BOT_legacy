from telebot import TeleBot
from telebot import types
#import g4f
import models
import os
import time
import speech_recognition as sr
from pydub import AudioSegment
import openai
#from g4f.Provider import FreeGpt, You, Chatgpt4Online, ChatgptDemoAi, ChatgptNext, ChatgptDemo, Gpt6, RetryProvider, GeekGpt, Liaobots, Theb, Raycast, FreeChatgpt, OpenaiChat, Bing, GptChatly, Aichat, GptGo, GeminiProChat, Koala, Aura, FakeGpt, AiAsk

GPT_MODELS = [
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-1106",
    "gpt-3.5-turbo-0125",
    "gpt-3.5-turbo-instruct",
    "gpt-3.5-turbo-instruct-0914",
    "gpt-3.5-turbo-16k-0613",
    "gpt-4",
    "gpt-4-0613",
    "gpt-4-1106-preview",
    "gpt-4-turbo-preview",
    "gpt-4-0125-preview",
]

openai.api_base = "https://api.proxyapi.ru/openai/v1"

with open("token.txt") as f:
    token = f.read().strip()

bot = TeleBot(token)

@bot.message_handler(commands=["copy"])
def copy(message):
    filename = f"data-{int(time.time())}.json"
    os.system(f"cp data.json copies/{filename}")
    with open(f"copies/{filename}", "rb") as f:
        bot.send_document(message.from_user.id, f)
    bot.send_message(message.chat.id, "–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞.")

@bot.message_handler(commands=["start"])
def cmd_start(message):
    data = models.Data.load()
    if data.get_user(message.from_user.id) is None:
        user = models.User(message.from_user.id)
        data.users.append(user)
        data.dump()
    bot.send_message(message.chat.id, "*–ü—Ä–∏–≤–µ—Ç! –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å, —Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å - —Å–ø—Ä–æ—Å–∏ –º–µ–Ω—è –æ —á—ë–º-–Ω–∏–±—É–¥—å. –ú–æ–¥–µ—à—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º. –¢—ã –º–æ–∂–µ—à—å –ø–æ–ø—Ä–æ—Å–∏—Ç—å –º–µ–Ω—è —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π —Ñ–∞–∫—Ç, –Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥, –∏–ª–∏ —Å–æ—á–∏–Ω–∏—Ç—å —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ.\n\n–ß–∞—Ç - https://t.me/+cRAejyefoDsyMTky.*", disable_web_page_preview=True, parse_mode="markdown")
    bot.send_message(message.chat.id, "*–Ø –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é —Å—Ü–µ–Ω–∞—Ä–∏–∏ - —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–æ–µ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è. –¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–≥—Ä–∞, –≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –¥–µ–≤—É—à–∫–∞, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –≤ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π —Å—Ñ–µ—Ä–µ, –∏–º–∏—Ç–∞—Ü–∏—è Linux-—Ç–µ—Ä–º–∏–Ω–∞–ª–∞ - –ø–æ—á—Ç–∏ –≤—Å—ë, —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ–∫—Å—Ç–æ–º, –º–æ–≥—É –¥–µ–ª–∞—Ç—å —è, –≥–ª–∞–≤–Ω–æ–µ –≤—ã–±—Ä–∞—Ç—å –Ω—É–∂–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π. –ù–∞–π—Ç–∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –º–æ–∂–Ω–æ –≤ –Ω–∞—à–µ–º —á–∞—Ç–µ - https://t.me/+cRAejyefoDsyMTky.*", disable_web_page_preview=True, parse_mode="markdown")

@bot.message_handler(commands=["clear"])
def clear_context(message):
    data = models.Data.load()
    user = data.get_user(message.from_user.id)
    s = data.get_scenario(user.settings.scenario)
    user.settings.conversation = [{"role": "system", "content": s}]
    data.dump()
    bot.send_message(message.from_user.id, "*üßπ –ü–µ—Ä–µ–ø–∏—Å–∫–∞ –æ—á–∏—â–µ–Ω–∞.*", parse_mode="markdown")

@bot.message_handler(commands=["model"])
def switch_model(message):
    data = models.Data.load()
    user = data.get_user(message.from_user.id)
    if message.text.lower() == "/model":
        bot.send_message(message.chat.id, "*–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n\n" + "\n".join(GPT_MODELS) + "*\n\n–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: " + user.settings.model, parse_mode="markdown")
        return None
    m = message.text[7:]
    if m in GPT_MODELS:
        user.settings.model = m
        data.dump()
        bot.send_message(message.chat.id, f"*–ú–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞: {m}.*", parse_mode="markdown")
    else:
        bot.send_message(message.chat.id, "*–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å. –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n\n" + "\n".join(GPT_MODELS) + "*", parse_mode="markdown")

@bot.message_handler(commands=["scenario"])
def choose_scenario(message):
    if len(message.text) > 10:
        scenario = message.text.split()[1]
    else:
        bot.send_message(message.chat.id, "*–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `/scenario [—Å—Ü–µ–Ω–∞—Ä–∏–π]`\n\n–°—Ü–µ–Ω–∞—Ä–∏–∏ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤ –Ω–∞—à–µ–º —á–∞—Ç–µ: https://t.me/+cRAejyefoDsyMTky.*", parse_mode="markdown", disable_web_page_preview=True)
        return None
    data = models.Data.load()
    user = data.get_user(message.from_user.id)
    s = data.get_scenario(scenario)
    if s is None:
        bot.send_message(message.chat.id, "–°—Ü–µ–Ω–∞—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    else:
        user.settings.scenario = scenario
        data.dump()
        bot.send_message(message.chat.id, f"*–í—ã–±—Ä–∞–Ω —Å—Ü–µ–Ω–∞—Ä–∏–π: {scenario}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/clear` –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ –±—ã –æ–Ω –∑–∞—Ä–∞–±–æ—Ç–∞–ª.\n\n–ß—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ —Å—Ü–µ–Ω–∞—Ä–∏—é –∞–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/scenario default.`\n\n–ï—Å–ª–∏ —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.*", parse_mode="markdown")

@bot.message_handler(commands=["make_scenario"])
def make_scenario(message):
    if len(message.text.split()) >= 3:
        data = models.Data.load()
        if message.text.split()[1] in data.scenarios.keys():
            bot.send_message(message.chat.id, "–°—Ü–µ–Ω–∞—Ä–∏–π —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
            return None
        cut = len(message.text.split()[1]) + 16
        data.scenarios[message.text.split()[1]] = message.text[cut:]
        data.dump()
        bot.send_message(message.chat.id, "*üóí –°—Ü–µ–Ω–∞—Ä–∏–π —Å–æ—Ö—Ä–∞–Ω—ë–Ω.*", parse_mode="markdown")
    else:
        bot.send_message(message.chat.id, "*–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /make_scenario [–Ω–∞–∑–≤–∞–Ω–∏–µ] [–ø—Ä–æ–º–ø—Ç]*")

@bot.message_handler(commands=["cancel"])
def cmd_cancel(message):
    data = models.Data.load()
    user = data.get_user(message.from_user.id)
    user.settings.conversation = user.settings.conversation[:-2]
    data.dump()
    a = bot.send_message(message.chat.id, "*üïì –û—Ç–º–∞—Ç—ã–≤–∞—é –≤—Ä–µ–º—è –Ω–∞–∑–∞–¥...*", parse_mode="markdown")
    time.sleep(1)
    bot.send_message(message.chat.id, "*‚ú® –í–∞—à –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∑–∞–ø—Ä–æ—Å —Å—Ç—ë—Ä—Ç –∏–∑ —ç—Ç–æ–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏!*", parse_mode="markdown")
    bot.delete_message(a.chat.id, a.message_id)

@bot.message_handler(commands=["sendall"])
def cmd_sendall(message):
    if message.from_user.id == 5373440151:
        data = models.Data.load()
        for usr in data.users:
            try:
                bot.forward_message(message.chat.id, usr.id, message.reply_to_message.message_id)
            except:
                print("–ê—à—ã–ø–∫–∞!")

@bot.message_handler(content_types=["text"])
def text_handler(message):
    handle_req(message, message.text)

@bot.message_handler(commands=["skip"])
def cmd_skip(message):
    handle_req(message, None, skipped=True)

@bot.message_handler(content_types=["voice"])
def vc_handler(message):
    msg = bot.send_message(message.chat.id, "*üîä –°–ª—É—à–∞—é...*", parse_mode="markdown")
    voice_message = bot.get_file(message.voice.file_id)
    voice_file = bot.download_file(voice_message.file_path)
    vcid = f"vc-{int(time.time()*100)}"
    with open(f"tmp/{vcid}.ogg", "wb") as f:
        f.write(voice_file)
    audio = AudioSegment.from_ogg(f"tmp/{vcid}.ogg")
    audio.export(f"tmp/{vcid}.wav", format="wav")
    os.remove(f"tmp/{vcid}.ogg")
    recognizer = sr.Recognizer()
    with sr.AudioFile(f"tmp/{vcid}.wav") as source:
        audio_data = recognizer.record(source)
        text = recognizer.recognize_google(audio_data, language='ru-RU')
    bot.send_message(message.chat.id, f"*‚ùó –û—Ç–≤–µ—á–∞—é –Ω–∞ –∑–∞–ø—Ä–æ—Å: {text}*", parse_mode="markdown")
    bot.delete_message(msg.chat.id, msg.message_id)
    handle_req(message, text)

def handle_req(message, text, skipped=False):
    wait = bot.send_message(message.chat.id, "*üë®‚Äçüíª –ü–µ—á–∞—Ç–∞—é...*", parse_mode="markdown")
    data = models.Data.load()
    user = data.get_user(message.from_user.id)
    success = False
    tries = 0
    while (not success) and (tries <= 5):
        try:
            conv = user.settings.conversation
            if not skipped:
                conv.append({"role": "user", "content": text})
            else:
                conv.append({"role": "system", "content": "continue"})
            #if "gpt-3.5-turbo" in user.settings.model:
            #    provider = RetryProvider([FreeGpt, Chatgpt4Online, ChatgptDemoAi, ChatgptNext, ChatgptDemo, Gpt6, GeekGpt, Liaobots, FreeChatgpt, GptChatly, Aichat, GptGo, FakeGpt, AiAsk])
            #elif "gpt-4" in user.settings.model:
            #    provider = RetryProvider([Bing, GeekGpt, Liaobots, Theb, Raycast, FreeChatgpt])
            #else:
            #    provider = None
            response = openai.ChatCompletion.create(
                model = user.settings.model,
                messages = conv,
                temperature = 0.7,
                stream = False
            )
            response = response.choices[0].message.content
            user.settings.conversation = conv[:]
            user.settings.conversation.append({"role": "assistant", "content": response})
            data.dump()
            bot.send_message(message.chat.id, response, parse_mode="markdown")
            bot.delete_message(wait.chat.id, wait.message_id)
            success = True
            return None
        except BaseException as err:
            print(repr(err))
            time.sleep(3)
            tries += 1
    bot.send_message(message.chat.id, "*‚õî –û—à–∏–±–∫–∞!*", parse_mode="markdown")


if __name__ == "__main__":
    bot.infinity_polling()
